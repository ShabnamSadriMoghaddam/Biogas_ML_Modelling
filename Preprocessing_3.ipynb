{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgNgU-LUwqqt"
      },
      "source": [
        "# Importing Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5zrn8DHylezi"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scienceplots\n",
        "\n",
        "\n",
        "import sklearn\n",
        "from sklearn.model_selection import *\n",
        "from sklearn.metrics import *\n",
        "from sklearn.preprocessing import *\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "from scipy import stats\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras_tuner\n",
        "\n",
        "\n",
        "import missingno\n",
        "import warnings\n",
        "import gc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yi6nRB-qws86"
      },
      "source": [
        "# Plotting Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "UJ-a40pAgyGI"
      },
      "outputs": [],
      "source": [
        "plt.rcdefaults()\n",
        "mpl_global_config = {\n",
        "    'figure.figsize': (7, 7),\n",
        "    'figure.dpi': 1000,\n",
        "    'font.size': 16,\n",
        "    'axes.labelsize': 14,\n",
        "    'axes.titlesize': 14,\n",
        "    'xtick.labelsize': 12,\n",
        "    'ytick.labelsize': 12,\n",
        "    'legend.fontsize': 8,\n",
        "    'lines.linewidth': 2,\n",
        "    'lines.markersize': 3,\n",
        "    'grid.linewidth': 0.75,\n",
        "    'savefig.dpi': 1000,\n",
        "    'savefig.transparent': False,\n",
        "    'savefig.bbox': 'tight',\n",
        "    'pdf.compression': 9,\n",
        "    'axes.axisbelow': True\n",
        "}\n",
        "plt.rcParams.update(mpl_global_config)\n",
        "plt.style.use(['science', 'nature', 'high-contrast', \"no-latex\"])\n",
        "\n",
        "\n",
        "colors = {\n",
        "    \"yellow\": \"#DDAA33\",\n",
        "    \"red\": \"#BB5566\",\n",
        "    \"blue\": \"#004488\",\n",
        "    \"black\": \"#000000\",\n",
        "    \"white\": \"#FFFFFF\"\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6V0DgZMo67oT"
      },
      "source": [
        "# Global Configuration Setting Controling Randomness, Trials, etc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Jjl2tp-cgypS"
      },
      "outputs": [],
      "source": [
        "sklearn.set_config(transform_output=\"pandas\")\n",
        "np.seterr(under='ignore')\n",
        "warnings.filterwarnings('ignore')\n",
        "SEED = 42\n",
        "tf.keras.utils.set_random_seed(SEED)\n",
        "n_trials = 50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Reading Imputated and Outlier Reconstructed Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Concatenation train and test dataset after imputation and outlier reconstruction\n",
        "\n",
        "# Load the CSV files\n",
        "df1 = pd.read_csv('X_train_Imputed_ROutlier.csv', index_col=0, parse_dates=True)\n",
        "df2 = pd.read_csv('X_test_Imputed_ROutlier.csv', index_col=0, parse_dates=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Concatenate DataFrames while keeping the index\n",
        "combined_df = pd.concat([df1, df2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sort the combined DataFrame by index\n",
        "sorted_combined_X = combined_df.sort_index()\n",
        "\n",
        "# Save the sorted DataFrame to a new CSV file\n",
        "sorted_combined_X.to_csv('sorted_combined_X_Imputed.csv', index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "Originaldf = pd.read_csv(\"OriginalData.csv\",\n",
        "                 dayfirst=True,\n",
        "                 parse_dates=True,\n",
        "                 index_col=\"Date\")\n",
        "\n",
        "Originaldf = Originaldf.dropna(subset=[\"Total Biogas Flowrate (m3/d)\"])\n",
        "\n",
        "\n",
        "y = Originaldf.pop(\"Total Biogas Flowrate (m3/d)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Merge the DataFrames along the columns\n",
        "preprocessed_df = pd.concat([sorted_combined_X, y], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "preprocessed_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "preprocessed_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Rename Columns by removing everything before and including the first double underscore\n",
        "preprocessed_df.columns = [col.split('__', 1)[-1] for col in preprocessed_df.columns]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "preprocessed_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the merged DataFrame to a new CSV file\n",
        "preprocessed_df.to_csv('preprocessed_df.csv', index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtMn_gbToLCs"
      },
      "source": [
        "# Visualization after imputation and outlier reconstruction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize after imputation \n",
        "num_variables = len(preprocessed_df.columns)  # Number of variables to plot\n",
        "num_rows = (num_variables + 1) // 2  # Calculate the number of rows needed\n",
        "\n",
        "fig, axes = plt.subplots(num_rows, 2, figsize=(13, 3 * num_rows))  # Adjust the size as needed, now with 2 columns\n",
        "\n",
        "for i, column in enumerate(preprocessed_df.columns):\n",
        "    ax = axes[i // 2, i % 2]  # Determine the correct subplot\n",
        "    ax.plot(preprocessed_df[column])\n",
        "    ax.set_title(column)\n",
        "    ax.set_xlabel('Index')\n",
        "    ax.set_ylabel(column)\n",
        "    ax.tick_params(axis='x', rotation=45)  # Rotate x-axis labels by 45 degrees\n",
        "\n",
        "# Adjust spacing between plots\n",
        "plt.subplots_adjust(hspace=0.5)  # Increase vertical space between rows\n",
        "plt.savefig(\"ImputedData.svg\", format='svg', dpi=1000, bbox_inches='tight')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Denoising"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data Denoising\n",
        "\n",
        "# Apply moving average filter\n",
        "window_size = 15\n",
        "moving_avg = preprocessed_df.rolling(window_size).mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Visualization after Denoising"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Vdre7L7JvUpx",
        "outputId": "661317b2-c918-4771-e8e4-335769cdbfa9"
      },
      "outputs": [],
      "source": [
        "num_variables = len(preprocessed_df.columns)  # Number of variables to plot\n",
        "num_rows = (num_variables + 1) // 2  # Calculate the number of rows needed\n",
        "\n",
        "fig, axes = plt.subplots(num_rows, 2, figsize=(13, 3 * num_rows))  # Adjust the size as needed, now with 2 columns\n",
        "\n",
        "for i, column in enumerate(preprocessed_df.columns):\n",
        "    ax = axes[i // 2, i % 2]  # Determine the correct subplot\n",
        "    ax.plot(preprocessed_df[column], label='Original Data')\n",
        "    ax.plot(moving_avg[column], label='Moving Average Denoised', linestyle='--')\n",
        "    ax.set_title(column)\n",
        "    ax.set_xlabel('Date')\n",
        "    ax.set_ylabel(column)\n",
        "    ax.tick_params(axis='x', rotation=45)  # Rotate x-axis labels by 45 degrees\n",
        "\n",
        "# Adjust spacing between plots\n",
        "plt.subplots_adjust(hspace=0.5)  # Increase vertical space between rows\n",
        "plt.savefig(\"Denoised Data.svg\", format='svg', dpi=300, bbox_inches='tight')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Drop rows with NaN values\n",
        "moving_avg_cleaned = moving_avg.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "moving_avg_cleaned.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "moving_avg_cleaned"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "moving_avg_cleaned.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the merged DataFrame to a new CSV file\n",
        "moving_avg_cleaned.to_csv('Denoised_df.csv', index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Create the Heatmaps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "feature_names = moving_avg_cleaned.columns\n",
        "\n",
        "\n",
        "# Set the figure size\n",
        "plt.figure(figsize=(12, 10))\n",
        "\n",
        "# Create the heatmap with adjusted parameters\n",
        "sns.heatmap(\n",
        "    moving_avg_cleaned.corr(method=\"pearson\"),\n",
        "    cmap=\"crest\",\n",
        "    annot=True,\n",
        "    fmt=\".2f\",  \n",
        "    linewidths=0.20,\n",
        "    cbar_kws={\"shrink\": .8},  # Shrink the color bar\n",
        "    annot_kws={\"size\": 10},  \n",
        "    xticklabels=feature_names,\n",
        "    yticklabels=feature_names\n",
        ")\n",
        "\n",
        "\n",
        "# Set the size of the x-tick labels\n",
        "plt.xticks(fontsize=13)  \n",
        "plt.yticks(fontsize=13)  \n",
        "\n",
        "\n",
        "# Add title and labels\n",
        "plt.title(\"Pearson's Rank Correlation Heatmap\", fontsize=16)\n",
        "plt.xlabel(\"Features/Target\", fontsize=16)\n",
        "plt.ylabel(\"Features/Target\", fontsize=16)\n",
        "\n",
        "\n",
        "plt.savefig(\"Pearson's Rank Correlation Heatmap.svg\", format='svg', dpi=1000, bbox_inches='tight')\n",
        "\n",
        "# Show the plot\n",
        "plt.tight_layout()  # Adjust layout to prevent clipping of tick-labels\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from scipy.stats import spearmanr  # Importing spearmanr for p-value calculation\n",
        "\n",
        "# Calculate Spearman's rank correlation and p-values\n",
        "corr_matrix, p_values = spearmanr(moving_avg_cleaned)\n",
        "\n",
        "# Create a heatmap for the correlation coefficients\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(\n",
        "    corr_matrix,\n",
        "    cmap=\"coolwarm\",  # Color map for the heatmap: Blues PiYG coolwarm Pastel1 Greens\n",
        "    annot=True,\n",
        "    fmt=\".2f\",\n",
        "    linewidths=0.20,\n",
        "    cbar_kws={\"shrink\": .8},\n",
        "    annot_kws={\"size\": 10},\n",
        "    xticklabels=moving_avg_cleaned.columns,\n",
        "    yticklabels=moving_avg_cleaned.columns\n",
        ")\n",
        "\n",
        "# Set the size of the x-tick labels\n",
        "plt.xticks(fontsize=13)  \n",
        "plt.yticks(fontsize=13)  \n",
        "\n",
        "# Add title and labels\n",
        "plt.title(\"Spearman's Rank Correlation Heatmap\", fontsize=16)\n",
        "plt.xlabel(\"Features/Target\", fontsize=16)\n",
        "plt.ylabel(\"Features/Target\", fontsize=16)\n",
        "\n",
        "plt.savefig(\"Spearman's Rank Correlation Heatmap.svg\", format='svg', dpi=1000, bbox_inches='tight')\n",
        "\n",
        "# Adjust layout\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Create a heatmap for the p-values\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(\n",
        "    p_values,\n",
        "    cmap=\"coolwarm\",  # Color map for the heatmap\n",
        "    annot=True,\n",
        "    fmt=\".2f\",\n",
        "    linewidths=0.20,\n",
        "    cbar_kws={\"shrink\": .8},\n",
        "    annot_kws={\"size\": 10},\n",
        "    xticklabels=moving_avg_cleaned.columns,\n",
        "    yticklabels=moving_avg_cleaned.columns\n",
        ")\n",
        "\n",
        "# Set the size of the x-tick labels\n",
        "plt.xticks(fontsize=13) \n",
        "plt.yticks(fontsize=13)  \n",
        "\n",
        "# Add title and labels for p-values\n",
        "plt.title(\"Spearman's Rank Correlation P-Values Heatmap\", fontsize=16)\n",
        "plt.xlabel(\"Features/Target\", fontsize=16)\n",
        "plt.ylabel(\"Features/Target\", fontsize=16)\n",
        "\n",
        "plt.savefig(\"Spearman's Rank Correlation P-Values Heatmap.svg\", format='svg', dpi=1000, bbox_inches='tight')\n",
        "\n",
        "# Adjust layout\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from scipy.stats import spearmanr  \n",
        "\n",
        "# Calculate Spearman's rank correlation and p-values\n",
        "corr_matrix, p_values = spearmanr(moving_avg_cleaned)\n",
        "\n",
        "# Create a heatmap for the correlation coefficients with significance annotations\n",
        "plt.figure(figsize=(14, 12))  \n",
        "\n",
        "# Create a mask for the annotations\n",
        "annot = np.empty(corr_matrix.shape, dtype=object)\n",
        "\n",
        "# Fill the annotation matrix with correlation coefficients and p-value significance\n",
        "for i in range(corr_matrix.shape[0]):\n",
        "    for j in range(corr_matrix.shape[1]):\n",
        "        if i == j:\n",
        "            annot[i, j] = f\"{corr_matrix[i, j]:.2f}\"  # Only show correlation coefficient on the diagonal\n",
        "        else:\n",
        "            significance = ''\n",
        "            if p_values[i, j] < 0.01:\n",
        "                significance = '**'\n",
        "            elif p_values[i, j] < 0.05:\n",
        "                significance = '*'\n",
        "            annot[i, j] = f\"{corr_matrix[i, j]:.2f}\\n{significance}\"  # Show correlation and significance on separate lines\n",
        "\n",
        "# Create the heatmap\n",
        "sns.heatmap(\n",
        "    corr_matrix,\n",
        "    cmap=\"coolwarm\",  # Color map for the heatmap\n",
        "    annot=annot,  # Use the annotated values\n",
        "    fmt='',  # No formatting for annotations\n",
        "    linewidths=0.20,\n",
        "    cbar_kws={\"shrink\": .8},\n",
        "    annot_kws={\"size\": 12},  \n",
        "    xticklabels=moving_avg_cleaned.columns,\n",
        "    yticklabels=moving_avg_cleaned.columns\n",
        ")\n",
        "\n",
        "# Improve label clarity\n",
        "plt.xticks(fontsize=12, rotation=45, ha='right')  # Rotate x-tick labels for better visibility\n",
        "plt.yticks(fontsize=12, rotation=0)  # Keep y-tick labels horizontal\n",
        "\n",
        "# Set title and labels\n",
        "plt.title(\"Spearman's Rank Correlation Heatmap with P-Value Significance\", fontsize=18)\n",
        "plt.xlabel(\"Features/Target\", fontsize=16)\n",
        "plt.ylabel(\"Features/Target\", fontsize=16)\n",
        "\n",
        "# Adjust layout\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"Spearman_Correlation_Heatmap_with_PValues.svg\", format='svg', dpi=1000, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import spearmanr  \n",
        "\n",
        "# Calculate Spearman's rank correlation and p-values\n",
        "corr_matrix, p_values = spearmanr(moving_avg_cleaned)\n",
        "\n",
        "# Create a mask for the upper triangle, including the diagonal\n",
        "mask = np.triu(np.ones_like(corr_matrix, dtype=bool), k=0)  \n",
        "\n",
        "# Create a heatmap for the correlation coefficients with significance annotations\n",
        "plt.figure(figsize=(14, 12))  \n",
        "\n",
        "# Create a mask for the annotations\n",
        "annot = np.empty(corr_matrix.shape, dtype=object)\n",
        "\n",
        "# Fill the annotation matrix with correlation coefficients and p-value significance\n",
        "for i in range(corr_matrix.shape[0]):\n",
        "    for j in range(corr_matrix.shape[1]):\n",
        "        if i == j:\n",
        "            annot[i, j] = f\"{corr_matrix[i, j]:.2f}\"  # Show correlation coefficient on the diagonal\n",
        "        elif i > j:  # Only show values in the lower triangle\n",
        "            significance = ''\n",
        "            if p_values[i, j] < 0.01:\n",
        "                significance = '**'\n",
        "            elif p_values[i, j] < 0.05:\n",
        "                significance = '*'\n",
        "            annot[i, j] = f\"{corr_matrix[i, j]:.2f}\\n{significance}\"  # Show correlation and significance on separate lines\n",
        "        else:\n",
        "            annot[i, j] = ''  # Leave upper triangle empty\n",
        "\n",
        "# Create the heatmap\n",
        "sns.heatmap(\n",
        "    corr_matrix,\n",
        "    mask=mask,  # Apply the mask to hide the upper triangle\n",
        "    cmap=\"coolwarm\",  # Color map for the heatmap\n",
        "    annot=annot,  # Use the annotated values\n",
        "    fmt='',  \n",
        "    linewidths=0.20,\n",
        "    cbar_kws={\"shrink\": .8},\n",
        "    annot_kws={\"size\": 12},  \n",
        "    xticklabels=moving_avg_cleaned.columns,\n",
        "    yticklabels=moving_avg_cleaned.columns\n",
        ")\n",
        "\n",
        "# Improve label clarity\n",
        "plt.xticks(fontsize=12, rotation=45, ha='right')  # Rotate x-tick labels for better visibility\n",
        "plt.yticks(fontsize=12, rotation=0)  # Keep y-tick labels horizontal\n",
        "\n",
        "# Set title and labels\n",
        "plt.title(\"Spearman's Rank Correlation Heatmap (Lower Triangle with Diagonal)\", fontsize=18)\n",
        "plt.xlabel(\"Features/Target\", fontsize=16)\n",
        "plt.ylabel(\"Features/Target\", fontsize=16)\n",
        "\n",
        "# Adjust layout\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"Spearman_Correlation_Heatmap_Lower_Triangle_with_Diagonal.svg\", format='svg', dpi=1000, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Identify Highly Correlated Features with P-Values\n",
        "highly_correlated_features = []\n",
        "\n",
        "# Calculate Spearman's rank correlation and p-values\n",
        "corr_matrix, p_values = spearmanr(moving_avg_cleaned)\n",
        "\n",
        "# Convert the correlation matrix to a DataFrame for easier access to columns\n",
        "corr_df = pd.DataFrame(corr_matrix, index=moving_avg_cleaned.columns, columns=moving_avg_cleaned.columns)\n",
        "\n",
        "# Iterate through the correlation matrix\n",
        "for i in range(len(corr_df.columns)):\n",
        "    for j in range(i + 1, len(corr_df.columns)):  # Adjusted to avoid duplicates\n",
        "        if corr_df.iloc[i, j] > 0.60 or corr_df.iloc[i, j] < -0.60:  \n",
        "            colname1 = corr_df.columns[i]\n",
        "            colname2 = corr_df.columns[j]\n",
        "            correlation_coefficient = corr_df.iloc[i, j]\n",
        "            # Calculate p-value for the correlation\n",
        "            _, p_value = spearmanr(moving_avg_cleaned[colname1], moving_avg_cleaned[colname2])\n",
        "            highly_correlated_features.append((colname1, colname2, correlation_coefficient, p_value))\n",
        "\n",
        "# Convert to DataFrame for better visualization\n",
        "highly_correlated_df = pd.DataFrame(highly_correlated_features, columns=['Feature 1', 'Feature 2', 'Correlation Coefficient', 'P-Value'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "highly_correlated_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save to a new CSV file\n",
        "highly_correlated_df.to_csv('highly_correlated_df.csv', index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Results of Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the selected features to be removed\n",
        "selected_features_to_be_removed = [\n",
        "    'VS of Influent Primary Sludge (%)',\n",
        "    'DS of Influent Waste Sludge (%)',\n",
        "    \"Influent Primary Sludge flowrate (m3/d)\",\n",
        "    \"Influent Waste Sludge flowrate (m3/d)\",\n",
        "    \"DS in Digesters (%)\",\n",
        "    \"Fatty Acid (mg/L)\",\n",
        "    'DS of effluent Sludge (%)',\n",
        "    'VS of effluent Sludge (%)',\n",
        "]\n",
        "\n",
        "# Keep the specified features and the target column\n",
        "df_filtered = moving_avg_cleaned.drop(columns=selected_features_to_be_removed)  # Corrected line\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_filtered"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Save the Preprossessed DataFrame as df,csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the preprocessed dataFrame to a new CSV file\n",
        "df_filtered.to_csv('df.csv', index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_filtered.isnull().sum()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
