{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Importing Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nopFpFQ--u--"
      },
      "outputs": [],
      "source": [
        "# importing packages\n",
        "from itertools import permutations, count\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn import set_config\n",
        "from sklearn.model_selection import (train_test_split,\n",
        "                                     cross_val_score,\n",
        "                                     cross_validate,\n",
        "                                     KFold)\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.compose import TransformedTargetRegressor\n",
        "import optuna\n",
        "from sklearn.metrics import *\n",
        "from sklearn.inspection import *\n",
        "import shap\n",
        "import lovelyplots\n",
        "import statsmodels.api as sm\n",
        "import gc\n",
        "import warnings\n",
        "\n",
        "\n",
        "import scienceplots\n",
        "\n",
        "\n",
        "import sklearn\n",
        "from sklearn.model_selection import *\n",
        "from sklearn.metrics import *\n",
        "from sklearn.preprocessing import *\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "from scipy import stats\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras_tuner\n",
        "\n",
        "\n",
        "import missingno\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Plotting Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "F_mkLXs0MWWS"
      },
      "outputs": [],
      "source": [
        "plt.rcdefaults()\n",
        "mpl_global_config = {\n",
        "    'figure.figsize': (7, 7),\n",
        "    'figure.dpi': 1000,\n",
        "    'font.size': 16,\n",
        "    'axes.labelsize': 14,\n",
        "    'axes.titlesize': 14,\n",
        "    'xtick.labelsize': 12,\n",
        "    'ytick.labelsize': 12,\n",
        "    'legend.fontsize': 8,\n",
        "    'lines.linewidth': 2,\n",
        "    'lines.markersize': 3,\n",
        "    'grid.linewidth': 0.75,\n",
        "    'savefig.dpi': 1000,\n",
        "    'savefig.transparent': False,\n",
        "    'savefig.bbox': 'tight',\n",
        "    'pdf.compression': 9,\n",
        "    'axes.axisbelow': True\n",
        "}\n",
        "plt.rcParams.update(mpl_global_config)\n",
        "plt.style.use(['science', 'nature', 'high-contrast', \"no-latex\"])\n",
        "\n",
        "\n",
        "colors = {\n",
        "    \"yellow\": \"#DDAA33\",\n",
        "    \"red\": \"#BB5566\",\n",
        "    \"blue\": \"#004488\",\n",
        "    \"black\": \"#000000\",\n",
        "    \"white\": \"#FFFFFF\"\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Global Configuration Setting Controling Randomness, Trials, etc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "KN67q6ey-wgF"
      },
      "outputs": [],
      "source": [
        "# config initialization\n",
        "set_config(transform_output=\"pandas\")\n",
        "np.seterr(under='ignore')\n",
        "warnings.filterwarnings('ignore')\n",
        "SEED = 0\n",
        "n_trials = 75\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# def evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "r5V7R9XiAUM9"
      },
      "outputs": [],
      "source": [
        "def evaluation(trained_model, X, y_real):\n",
        "\n",
        "    y_pred = trained_model.predict(X)\n",
        "\n",
        "    mse = mean_squared_error(y_real, y_pred, squared=True)\n",
        "    rmse = mean_squared_error(y_real, y_pred, squared=False)\n",
        "    mae = mean_absolute_error(y_real, y_pred)\n",
        "    r2 = r2_score(y_real, y_pred)\n",
        "    maxerror = max_error(y_real, y_pred)\n",
        "    mape = mean_absolute_percentage_error(y_real, y_pred)\n",
        "\n",
        "    return {\"MeanSquaredError\":mse,\n",
        "            \"RootMeanSquaredError\": rmse,\n",
        "            \"MeanAbsoluteError\": mae,\n",
        "            \"R2\": r2,\n",
        "            \"MaxError\": maxerror,\n",
        "            \"MAPE\": mape}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Read the Preprocessed Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5RBqBmW-0IN",
        "outputId": "79e5812f-336e-4c75-b2ca-b049cbf6416d"
      },
      "outputs": [],
      "source": [
        "# reading the dataset\n",
        "df = pd.read_csv(\"df.csv\",\n",
        "                 dayfirst=True,\n",
        "                 parse_dates=True,\n",
        "                 index_col=\"Date\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "18Mpqkln-6pV"
      },
      "outputs": [],
      "source": [
        "data_summary = df.describe()\n",
        "data_summary.loc[\"Missing Values Ratio\"] = df.isnull().sum().divide(len(df))\n",
        "data_summary.loc[\"Unique Values Ratio\"] = df.nunique().divide(len(df))\n",
        "data_summary.loc[\"Kurtosis\"] = df.kurtosis()\n",
        "data_summary.loc[\"Skewness\"] = df.skew()\n",
        "data_summary.T.to_csv(\"data_summary.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C0e9Jdwk94iz"
      },
      "outputs": [],
      "source": [
        "data_summary.T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Separating X and y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ASGkjzew60i",
        "outputId": "efe8fa32-950c-4aa5-e93a-db47c987134c"
      },
      "outputs": [],
      "source": [
        "X = df.drop(columns=[\"Total Biogas Flowrate (m3/d)\"])\n",
        "y = df.loc[: , \"Total Biogas Flowrate (m3/d)\"]\n",
        "print(f\"dataframe shape: {df.shape}\\n\"\\\n",
        "      f\"features shape: {X.shape}\\n\"\\\n",
        "      f\"target shape: {y.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Train and Test Split and Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUrvK4gS_0pF",
        "outputId": "4d2d6691-10df-4f37-a830-4b43607d920c"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.30,\n",
        "    random_state=SEED\n",
        ")\n",
        "\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Hyperparameter Optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAGURTs489bm",
        "outputId": "64719cbc-20b8-4595-94d9-4d734acf227e"
      },
      "outputs": [],
      "source": [
        "# train a Decision Tree model with tpe sampler and median pruner\n",
        "def objective_dt(trial):\n",
        "\n",
        "    dt_params = {\n",
        "            \"max_depth\": trial.suggest_int(\"max_depth\", 2, 15),\n",
        "            \"min_samples_leaf\": trial.suggest_float(\"min_samples_leaf\", 0.01, 0.5),\n",
        "        }\n",
        "\n",
        "    model = DecisionTreeRegressor(random_state=SEED, **dt_params)\n",
        "\n",
        "    score = -np.mean(\n",
        "        cross_val_score(\n",
        "                model,\n",
        "                X_train,\n",
        "                y_train,\n",
        "                cv=KFold(n_splits=5),\n",
        "                n_jobs=-1,\n",
        "                scoring='neg_mean_squared_error')\n",
        "        )\n",
        "\n",
        "    return score\n",
        "\n",
        "study_dt = optuna.create_study(\n",
        "    direction=\"minimize\",\n",
        "    sampler=optuna.samplers.TPESampler(seed=SEED),\n",
        "    pruner=optuna.pruners.HyperbandPruner()\n",
        ")\n",
        "\n",
        "study_dt.optimize(objective_dt, n_trials=n_trials)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEblnp0T9uc4",
        "outputId": "9d1549df-be55-4b16-9db5-c40375c27b56"
      },
      "outputs": [],
      "source": [
        "# train a Random Forest model with tpe sampler and median pruner\n",
        "def objective_rf(trial):\n",
        "\n",
        "    rf_params = {\n",
        "            \"max_features\": trial.suggest_float(\"max_features\", 0.3, 1),\n",
        "            \"max_depth\": trial.suggest_int(\"max_depth\", 2, 15),\n",
        "            \"min_samples_leaf\": trial.suggest_float(\"min_samples_leaf\", 0.01, 0.5),\n",
        "            \"bootstrap\": trial.suggest_categorical(\"bootstrap\", [False, True]),\n",
        "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 10, 200)\n",
        "        }\n",
        "\n",
        "    model = RandomForestRegressor(random_state=SEED, **rf_params)\n",
        "\n",
        "\n",
        "    score = -np.mean(\n",
        "        cross_val_score(\n",
        "                model,\n",
        "                X_train,\n",
        "                y_train,\n",
        "                cv=KFold(n_splits=5),\n",
        "                n_jobs=-1,\n",
        "                scoring='neg_mean_squared_error')\n",
        "        )\n",
        "\n",
        "    return score\n",
        "\n",
        "study_rf = optuna.create_study(\n",
        "    direction=\"minimize\",\n",
        "    sampler=optuna.samplers.TPESampler(seed=SEED),\n",
        "    pruner=optuna.pruners.HyperbandPruner()\n",
        "\n",
        ")\n",
        "\n",
        "study_rf.optimize(objective_rf, n_trials=n_trials)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XT_iEdoa-e6h",
        "outputId": "e4387d07-d7d9-43bc-ef37-23bd2825d849"
      },
      "outputs": [],
      "source": [
        "# train an XBGBoost model with tpe sampler and median pruner\n",
        "def objective_xgb(trial):\n",
        "\n",
        "    params = {\n",
        "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 10, 5000),\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 1.0, log=True),\n",
        "        \"max_delta_step\": trial.suggest_int(\"max_delta_step\", 0, 20),\n",
        "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\",1e-9, 100.0, log=True),\n",
        "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-9, 100.0, log=True),\n",
        "        \"subsample\": trial.suggest_float(\"subsample\", 0.1, 1.0, log=True),\n",
        "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.1, 1.0, log=True),\n",
        "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 15),\n",
        "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
        "        \"gamma\": trial.suggest_float(\"gamma\", 0.1, 0.5, log=True),\n",
        "        \"scale_pos_weight\": trial.suggest_float(\"scale_pos_weight\", 1e-6, 500, log=True)\n",
        "    }\n",
        "\n",
        "\n",
        "    model = XGBRegressor(random_state=SEED, objective=\"reg:squarederror\", **params)\n",
        "\n",
        "    score = -np.mean(\n",
        "        cross_val_score(\n",
        "                model,\n",
        "                X_train,\n",
        "                y_train,\n",
        "                cv=KFold(n_splits=5),\n",
        "                n_jobs=-1,\n",
        "                scoring='neg_mean_squared_error')\n",
        "        )\n",
        "\n",
        "    return score\n",
        "\n",
        "study_xgb = optuna.create_study(\n",
        "    direction=\"minimize\",\n",
        "    sampler=optuna.samplers.TPESampler(seed=SEED),\n",
        "    pruner=optuna.pruners.HyperbandPruner()\n",
        ")\n",
        "\n",
        "study_xgb.optimize(objective_xgb, n_trials=n_trials)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_hps = {\n",
        "    \"DecisionTree\": study_dt.best_params,\n",
        "    \"RandomForest\": study_rf.best_params,\n",
        "    \"XGBoost\": study_xgb.best_params,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_hps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_hps = {'DecisionTree': {'max_depth': 14, 'min_samples_leaf': 0.010039169930176879},\n",
        "            'RandomForest': {'max_features': 0.38554104875151896,\n",
        "            'max_depth': 10,\n",
        "            'min_samples_leaf': 0.010168225931922027,\n",
        "            'bootstrap': False,\n",
        "            'n_estimators': 124},\n",
        "            'XGBoost': {'n_estimators': 4860,\n",
        "            'learning_rate': 0.49003165411341526,\n",
        "            'max_delta_step': 20,\n",
        "            'reg_lambda': 1.1231181925328875e-05,\n",
        "            'reg_alpha': 3.426318577751964e-08,\n",
        "            'subsample': 0.89607666469783,\n",
        "            'colsample_bytree': 0.8147384539995441,\n",
        "            'max_depth': 4,\n",
        "            'min_child_weight': 10,\n",
        "            'gamma': 0.1296891015376799,\n",
        "            'scale_pos_weight': 2.2740058630279575e-05}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Fitting the Models with Best HPs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "2_KMb_YbAbgN"
      },
      "outputs": [],
      "source": [
        "\n",
        "trained_models = {\n",
        "    \"DecisionTree\": DecisionTreeRegressor(random_state=SEED,\n",
        "                                          **best_hps[\"DecisionTree\"]).fit(X_train, y_train),\n",
        "\n",
        "    \"RandomForest\": RandomForestRegressor(random_state=SEED,\n",
        "                                          **best_hps[\"RandomForest\"]).fit(X_train, y_train),\n",
        "\n",
        "\n",
        "    \"XGBoost\": XGBRegressor(random_state=SEED,\n",
        "                            **best_hps[\"XGBoost\"],\n",
        "                            objective=\"reg:squarederror\").fit(X_train, y_train),\n",
        "\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "twQCsMdNMTYL"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame.from_dict(best_hps, orient=\"index\").T.to_csv(\"hyperparameters_when_all_features_are_chosen.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "9wlhEZC-AebG"
      },
      "outputs": [],
      "source": [
        "evaluations_dictionary = {\n",
        "    \"DecisionTree_Train\": evaluation(trained_models[\"DecisionTree\"],\n",
        "                                     X_train, y_train),\n",
        "    \"DecisionTree_Test\": evaluation(trained_models[\"DecisionTree\"],\n",
        "                                    X_test, y_test),\n",
        "\n",
        "    \"RandomForest_Train\": evaluation(trained_models[\"RandomForest\"],\n",
        "                                     X_train, y_train),\n",
        "    \"RandomForest_Test\": evaluation(trained_models[\"RandomForest\"],\n",
        "                                    X_test, y_test),\n",
        "\n",
        "    \"XGBoost_Train\": evaluation(trained_models[\"XGBoost\"],\n",
        "                                X_train, y_train),\n",
        "    \"XGBoost_Test\": evaluation(trained_models[\"XGBoost\"],\n",
        "                               X_test, y_test),\n",
        "\n",
        "}\n",
        "\n",
        "evaluation_df = pd.DataFrame(evaluations_dictionary)\n",
        "evaluation_df.T.to_csv(\"model_evaluation.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "AeZcV_vHfEn0",
        "outputId": "2cc0f932-f745-4b98-84a3-66c311a72247"
      },
      "outputs": [],
      "source": [
        "evaluation_df.T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.style.use(['science', 'nature', 'high-contrast', \"no-latex\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for model in trained_models.keys():\n",
        "    for dataset in [(\"Train\", X_train, y_train), (\"Test\", X_test, y_test)]:\n",
        "        data_type, X_data, y_data = dataset\n",
        "        fig, ax = plt.subplots(figsize=(7, 7))\n",
        "        PredictionErrorDisplay.from_estimator(\n",
        "            trained_models[model],\n",
        "            X_data,\n",
        "            y_data,\n",
        "            kind=\"actual_vs_predicted\",\n",
        "            scatter_kwargs={\"alpha\": 1,\n",
        "                            \"color\": \"#004488\",  \n",
        "                            \"label\": f\"{data_type} MAE: {int(evaluation_df.loc['MeanAbsoluteError', f'{model}_{data_type}'].round(0))}\", \n",
        "                            \"s\":45},\n",
        "            line_kwargs={\"color\": \"black\"},\n",
        "            ax=ax)\n",
        "\n",
        "        ax.set_ylabel(f\"Actual {y.name}\", fontsize=14, fontweight='bold')  \n",
        "        ax.set_xlabel(f\"Predicted {y.name}\", fontsize=14, fontweight='bold')  \n",
        "        ax.legend(fontsize=9, loc=\"upper left\", fancybox=True, shadow=True, ncol=1, frameon=False)  \n",
        "        ax.tick_params(axis='x', labelsize=12)  # Increased font size for x-axis numbers\n",
        "        ax.tick_params(axis='y', labelsize=12)  # Increased font size for y-axis numbers\n",
        "        \n",
        "        from matplotlib.ticker import AutoMinorLocator  # Import minor locator\n",
        "        ax.xaxis.set_minor_locator(AutoMinorLocator(2))  # Add minor ticks to x-axis\n",
        "        ax.yaxis.set_minor_locator(AutoMinorLocator(2))  # Add minor ticks to y-axis\n",
        "        \n",
        "        ax.grid(False)  # Disable gridlines\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f\"evaluation actual_vs_predicted_{model}_{data_type}.svg\")\n",
        "        # plt.close()\n",
        "        # gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ki-q5uf1jl3o"
      },
      "outputs": [],
      "source": [
        "for model in trained_models.keys():\n",
        "    fig, ax = plt.subplots(figsize=(7, 7))\n",
        "    PredictionErrorDisplay.from_estimator(\n",
        "        trained_models[model],\n",
        "        X_test,\n",
        "        y_test,\n",
        "        kind=\"residual_vs_predicted\",\n",
        "        scatter_kwargs={\"alpha\": 1,\n",
        "                        \"s\":40,\n",
        "                        \"color\": \"#DD3C2D\",\n",
        "                        \"label\": f\"Test R2: {evaluation_df.loc['R2', f'{model}_Test'].round(3)}\",\n",
        "                        },\n",
        "        line_kwargs={\"color\": \"black\"},\n",
        "        ax=ax)\n",
        "\n",
        "\n",
        "    PredictionErrorDisplay.from_estimator(\n",
        "        trained_models[model],\n",
        "        X_train,\n",
        "        y_train,\n",
        "        kind=\"residual_vs_predicted\",\n",
        "        scatter_kwargs={\"alpha\": 0.3,\n",
        "                        \"s\":40,\n",
        "                        \"color\": \"#364B9A\",\n",
        "                        \"label\": f\"Train R2: {evaluation_df.loc['R2', f'{model}_Train'].round(3)}\",\n",
        "                        \"marker\": \"X\"\n",
        "                        },\n",
        "        line_kwargs={\"color\": \"black\"},\n",
        "        ax=ax)\n",
        "\n",
        "\n",
        "\n",
        "    ax.set_xlabel(f\"Predicted {y.name}\", fontsize=14)\n",
        "    ax.set_ylabel(f\"Residuals\\n(Actual - Predicted)\", fontsize=14)\n",
        "    ax.legend(fontsize=9, loc=\"lower left\", fancybox=True, shadow=True, ncol=1)\n",
        "    ax.tick_params(axis='x', labelsize=9)\n",
        "    ax.tick_params(axis='y', labelsize=9)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"evaluation_residual_{model}.svg\", format='svg', dpi=1000, bbox_inches='tight')\n",
        "    # plt.close()\n",
        "    # gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dWj90ljMnhs-"
      },
      "outputs": [],
      "source": [
        "for model in trained_models.keys():\n",
        "    residuals = y_test - trained_models[model].predict(X_test)\n",
        "    fig, ax = plt.subplots(figsize=(7, 7))\n",
        "    sm.qqplot(residuals, line ='q', ax=ax)\n",
        "    ax.set_ylabel(\"Sample Quantiles\", fontsize=14)\n",
        "    ax.set_xlabel(\"Theoretical Quantiles\", fontsize=14)\n",
        "    ax.tick_params(axis='x', labelsize=9)\n",
        "    ax.tick_params(axis='y', labelsize=9)\n",
        "    plt.savefig(f\"evaluation qqplot_{model}.svg\", format='svg', dpi=1000, bbox_inches='tight')\n",
        "    # plt.close()\n",
        "    # gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "asFeW8Xbqpet"
      },
      "outputs": [],
      "source": [
        "for model in trained_models.keys():\n",
        "    residuals_test = y_test - trained_models[model].predict(X_test)\n",
        "    fig, ax = plt.subplots(figsize=(7, 7))\n",
        "    ax.text(0.63, 0.7,\n",
        "            f\"Mean: {residuals_test.mean().round(3)}\\nStd: {residuals_test.std().round(3)}\",\n",
        "            transform=ax.transAxes, fontsize=9)\n",
        "    sns.kdeplot(residuals_test, ax=ax, label=f\"{model}\", color=\"#6EA5CD\", linewidth=2)\n",
        "    ax.set_ylabel(\"Density\", fontsize=14)\n",
        "    ax.set_xlabel(\"Error\", fontsize=14)\n",
        "    plt.legend(fontsize=9, loc=\"upper left\", fancybox=True, shadow=True, ncols=1)\n",
        "    ax.tick_params(axis='x', labelsize=9)\n",
        "    ax.tick_params(axis='y', labelsize=9)\n",
        "    plt.savefig(f\"Evaluation_kde_residuals_{model}.svg\", format='svg', dpi=1000, bbox_inches='tight')\n",
        "#     plt.close()\n",
        "#     gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjmqixFedGGK"
      },
      "source": [
        "## Explanation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## SHAP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "cCOYcexadFrl"
      },
      "outputs": [],
      "source": [
        "plt.rcdefaults()\n",
        "# plt.style.use()\n",
        "\n",
        "\n",
        "mpl_global_config = {\n",
        "    'figure.dpi': 100,\n",
        "    'savefig.dpi': 1200,\n",
        "    'savefig.transparent': False,\n",
        "    'savefig.bbox': 'tight',\n",
        "    'axes.axisbelow': True,\n",
        "    'axes.spines.top': True,\n",
        "    'axes.spines.right': True,\n",
        "    'axes.spines.bottom': True,\n",
        "    'axes.spines.left': True,\n",
        "    \"axes.grid\": True,\n",
        "    'grid.linewidth': 0.3,\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "plt.rcParams.update(mpl_global_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "3ES1qKrU169U"
      },
      "outputs": [],
      "source": [
        "explainer = shap.TreeExplainer(trained_models[\"XGBoost\"])\n",
        "shap_values = explainer.shap_values(X_test)\n",
        "shap_interaction_values = explainer.shap_interaction_values(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7Jdyx9PYL3C",
        "outputId": "8b0645a5-e3ea-443b-943b-31633df6780d"
      },
      "outputs": [],
      "source": [
        "shap.summary_plot(shap_values, X_test, plot_type=\"bar\", color=\"#DD3C2D\", show=False, max_display=30)\n",
        "plt.gca().spines['top'].set_visible(True)\n",
        "plt.gca().spines['right'].set_visible(True)\n",
        "plt.gca().spines['bottom'].set_visible(True)\n",
        "plt.gca().spines['left'].set_visible(True)\n",
        "plt.gca().spines['top'].set_color('black')\n",
        "plt.gca().spines['right'].set_color('black')\n",
        "plt.gca().spines['bottom'].set_color('black')\n",
        "plt.gca().spines['left'].set_color('black')\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"Explanation_FeatureImportancePlot.svg\", format='svg', dpi=1000, bbox_inches='tight')\n",
        "# plt.close()\n",
        "# gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import shap\n",
        "\n",
        "# Generate the SHAP summary plot\n",
        "shap.summary_plot(shap_values, X_test, show=False, max_display=30)\n",
        "\n",
        "# Customize spines (axis lines)\n",
        "ax = plt.gca()  # Get current axes\n",
        "ax.spines['top'].set_visible(True)\n",
        "ax.spines['right'].set_visible(True)\n",
        "ax.spines['bottom'].set_visible(True)\n",
        "ax.spines['left'].set_visible(True)\n",
        "\n",
        "# Set spine colors and widths\n",
        "for spine in ax.spines.values():\n",
        "    spine.set_color('black')  # Set spine color to black\n",
        "    spine.set_linewidth(2)     # Make spines bolder\n",
        "\n",
        "# Set title and labels in bold black\n",
        "plt.title('SHAP Summary Plot', color='black', fontsize=14, fontweight='bold')  # Title in bold black\n",
        "\n",
        "# Customize tick parameters to bold the numbers\n",
        "ax.tick_params(axis='both', which='major', labelcolor='black', labelsize=12) \n",
        "for tick in ax.get_xticklabels() + ax.get_yticklabels():  # Get all tick labels\n",
        "    tick.set_fontsize(12)  # Increased font size for tick labels\n",
        "    tick.set_fontweight('bold')  # Set font weight to bold\n",
        "\n",
        "# Increase space between x label and axis\n",
        "ax.set_xlabel('SHAP Value (impact on model output)', labelpad=15, color='black', fontsize=12, fontweight='bold')  # Adjust labelpad as needed\n",
        "\n",
        "# Save the plot \n",
        "plt.savefig(\"Explanation_SummaryImportancePlot_2.svg\", format='svg', dpi=3000, bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import shap\n",
        "\n",
        "for main_feature in list(X_test.columns):\n",
        "    fig, ax = plt.subplots(figsize=(7, 7))  \n",
        "    \n",
        "    # Generate the SHAP dependence plot\n",
        "    shap.dependence_plot(\n",
        "        (main_feature, main_feature),\n",
        "        shap_interaction_values, X_test,\n",
        "        display_features=X_test.iloc[:, :],\n",
        "        dot_size=50,  # Increase dot size for better visibility\n",
        "        show=False,\n",
        "        ax=ax\n",
        "    )\n",
        "\n",
        "    # Customize spines (axis lines)\n",
        "    ax.spines['top'].set_visible(True)\n",
        "    ax.spines['right'].set_visible(True)\n",
        "    ax.spines['bottom'].set_visible(True)\n",
        "    ax.spines['left'].set_visible(True)\n",
        "    \n",
        "    # Set spine colors and widths\n",
        "    for spine in ax.spines.values():\n",
        "        spine.set_color('black')  # Set spine color to black\n",
        "        spine.set_linewidth(2)     # Make spines bolder\n",
        "\n",
        "    # Set title and labels in bold black\n",
        "    plt.title(f'SHAP Dependence Plot for {main_feature}', color='black', fontsize=14, fontweight='bold')  # Title in bold black\n",
        "    plt.xlabel(main_feature, color='black', fontsize=12, fontweight='bold')  # X-axis label in bold black\n",
        "    plt.ylabel('SHAP Value', color='black', fontsize=12, fontweight='bold')  # Y-axis label in bold black\n",
        "\n",
        "    # Customize tick parameters to bold the numbers\n",
        "    ax.tick_params(axis='both', which='major', labelcolor='black', labelsize=10)  # Major ticks in black\n",
        "    for tick in ax.get_xticklabels() + ax.get_yticklabels():  # Get all tick labels\n",
        "        tick.set_fontsize(10)  \n",
        "        tick.set_fontweight('bold')  \n",
        "\n",
        "    # Manually plot the markers in blue\n",
        "    scatter = ax.collections[0]  # Get the scatter collection from the dependence plot\n",
        "    scatter.set_facecolor('blue') \n",
        "\n",
        "    # Save the plot \n",
        "    main_feature_safe = main_feature.replace(\"/\", \"\")  # Remove slashes from feature names\n",
        "    plt.savefig(f\"Explanation_Singular_{main_feature_safe}_dependence_plot.svg\", format='svg', dpi=3000, bbox_inches='tight')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# compute SHAP values\n",
        "shap_values = explainer(X_test[:1000])\n",
        "\n",
        "shap.plots.heatmap(shap_values, instance_order=shap_values.sum(1))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "shap.plots.scatter(shap_values[:, \"Temperature (Degrees Celsius)\"], color=shap_values[:, \"Alkalinity (mg CaCO3/L)\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "clustering = shap.utils.hclust(X, y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "shap.plots.bar(shap_values, clustering=clustering, clustering_cutoff=0.8, show=False)\n",
        "\n",
        "# Customize the ticks and labels for the existing plot\n",
        "plt.xticks(fontsize=18, fontweight=\"bold\", color=\"black\")  \n",
        "plt.yticks(fontsize=18, fontweight=\"bold\", color=\"black\")  \n",
        "\n",
        "# Customize the axis labels\n",
        "plt.xlabel(plt.gca().get_xlabel(), fontsize=14, fontweight=\"bold\", color=\"black\")  \n",
        "plt.ylabel(plt.gca().get_ylabel(), fontsize=14, fontweight=\"bold\", color=\"black\")  \n",
        "\n",
        "\n",
        "plt.savefig(\"bar_plot.svg\", format='svg', dpi=3000, bbox_inches='tight')\n",
        "\n",
        "# Display the updated plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "518jqDlKxIQT"
      },
      "outputs": [],
      "source": [
        "# download results\n",
        "import os\n",
        "from zipfile import ZipFile\n",
        "\n",
        "with ZipFile(\"TreeBasedModels.zip\", \"w\") as z:\n",
        "    for file in os.listdir():\n",
        "        if file.endswith((\".svg\", \".csv\")):\n",
        "            z.write(file)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
